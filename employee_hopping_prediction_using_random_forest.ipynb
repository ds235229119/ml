{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkUtYvT-w9aA"
      },
      "outputs": [],
      "source": [
        "# Step 1: Understand Data\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"Employee Hopping.csv\")\n",
        "print(data.head())\n",
        "print(data.shape)\n",
        "print(data.columns)\n",
        "print(data.dtypes)\n",
        "print(data.info())\n",
        "print(data['Target_Column'].value_counts())  # Replace 'Target_Column' with the actual target column name\n",
        "\n",
        "# Step 2: Extract X and y\n",
        "X = data.drop(['Target_Column'], axis=1)  # Replace 'Target_Column' with the actual target column name\n",
        "y = data['Target_Column']\n",
        "\n",
        "# Step 3: Feature Engineering\n",
        "X = pd.get_dummies(X, columns=['Categorical_Column1', 'Categorical_Column2', ...])  # Replace with actual categorical columns\n",
        "\n",
        "# Step 4: Check shape of X and y\n",
        "print(X.shape)\n",
        "\n",
        "# Step 5: Model Development\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "rf_classifier = RandomForestClassifier()\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Step 6: Testing\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Step 7: Feature Importance Value\n",
        "feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': rf_classifier.feature_importances_})\n",
        "print(feature_importance)\n",
        "\n",
        "\n",
        "# Step 8: Visualize RF Decision Tree using graphviz\n",
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "\n",
        "# Choose one tree from the forest (e.g., first tree)\n",
        "tree_to_visualize = 0\n",
        "tree_dot_data = export_graphviz(rf_classifier.estimators_[tree_to_visualize],\n",
        "                                out_file=None,\n",
        "                                feature_names=X.columns,\n",
        "                                class_names=['Stay', 'Leave'],  # Replace with actual class names\n",
        "                                filled=True, rounded=True, special_characters=True)\n",
        "\n",
        "graph = graphviz.Source(tree_dot_data)\n",
        "graph.render(\"RandomForestTree\")  # Save the visualization as a file\n",
        "\n",
        "# Step 9: Fit RF models with a range of tree numbers and print Out-Of-Bag error\n",
        "range_trees = [15, 20, 30, 40, 50, 100, 150, 200, 300, 400]\n",
        "oob_errors = []\n",
        "\n",
        "for n_trees in range_trees:\n",
        "    rf_classifier.set_params(n_estimators=n_trees, warm_start=True, oob_score=True)\n",
        "    rf_classifier.fit(X_train, y_train)\n",
        "    oob_errors.append(1 - rf_classifier.oob_score_)\n",
        "\n",
        "    print(f\"Number of Trees: {n_trees}, Out-Of-Bag Error: {1 - rf_classifier.oob_score_}\")\n",
        "\n",
        "# Step 10: Plot OOB error for each tree\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range_trees, oob_errors, marker='o')\n",
        "plt.xlabel(\"Number of Trees\")\n",
        "plt.ylabel(\"Out-Of-Bag Error\")\n",
        "plt.title(\"Out-Of-Bag Error vs. Number of Trees\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 11: Compare with Decision Tree Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "# Create Decision Tree Classifier\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "y_pred_dt = dt_classifier.predict(X_test)\n",
        "\n",
        "# Visualize Decision Tree\n",
        "dt_dot_data = tree.export_graphviz(dt_classifier,\n",
        "                                   out_file=None,\n",
        "                                   feature_names=X.columns,\n",
        "                                   class_names=['Stay', 'Leave'],  # Replace with actual class names\n",
        "                                   filled=True, rounded=True, special_characters=True)\n",
        "\n",
        "dt_graph = graphviz.Source(dt_dot_data)\n",
        "dt_graph.render(\"DecisionTree\")  # Save the visualization as a file\n",
        "\n",
        "# Print accuracy score and classification report for Decision Tree\n",
        "print(\"Decision Tree Accuracy Score:\", accuracy_score(y_test, y_pred_dt))\n",
        "print(\"Decision Tree Classification Report:\\n\", classification_report(y_test, y_pred_dt))\n",
        "\n",
        "# Compare RF and DT models\n",
        "print(\"\\nComparison between RF and DT models:\")\n",
        "print(\"RF Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
        "print(\"DT Accuracy Score:\", accuracy_score(y_test, y_pred_dt))\n"
      ],
      "metadata": {
        "id": "4TyPnCsIyysJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}